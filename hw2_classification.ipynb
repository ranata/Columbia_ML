{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data\n",
    "X_train = np.genfromtxt('X_train_C.csv', delimiter=',')\n",
    "y_train = np.genfromtxt('Y_train_C.csv', delimiter=',')\n",
    "X_test = np.genfromtxt('X_test_C.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store number of unique training labels and their frequency\n",
    "Y, n_y = np.unique(y_train, return_counts=True)\n",
    "print(list(zip(Y, n_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn prior probablity (pi_hat), MLE for class conditional mean (mu_hat) & class conditional covariance (sigma_hat)\n",
    "pi_hat = []\n",
    "mu_hat = []\n",
    "sigma_hat = []\n",
    "for y, count_y in zip(Y, n_y):\n",
    "    \n",
    "    pi_hat_y = count_y/np.sum(n_y) # class prior\n",
    "    pi_hat.append(pi_hat_y)\n",
    "    mu_hat_y = np.dot((y_train == y), X_train)/count_y #class conditional mean\n",
    "    mu_hat.append(mu_hat_y)\n",
    "    X_train_y = X_train[y_train.astype(int) == np.int(y), :] #subetting X_train by class\n",
    "    \n",
    "    x_mu_hat_dev_y = X_train_y - mu_hat_y\n",
    "        \n",
    "    sigma_hat_y = np.dot(x_mu_hat_dev_y.T, x_mu_hat_dev_y)/(count_y) #class conditional covariance since this is QDA\n",
    "    \n",
    "    sigma_hat.append(sigma_hat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 10)\n"
     ]
    }
   ],
   "source": [
    "# predicting for X_test\n",
    "# calculate QDA probability disctribution for each test sample\n",
    "y_test = []\n",
    "    \n",
    "for x in X_test:\n",
    "    \n",
    "    f_x_hat = []\n",
    "    for y in Y:\n",
    "        idx = np.int(y)\n",
    "        x_mu_hat_dev_y = x - mu_hat[idx]\n",
    "\n",
    "        coefficient = pi_hat[idx]/np.sqrt(np.linalg.det(sigma_hat[idx]))\n",
    "        \n",
    "        power_value = -(1/2)*(x_mu_hat_dev_y.T@np.linalg.inv(sigma_hat[idx])@x_mu_hat_dev_y)\n",
    " \n",
    "        f_x_hat_y = coefficient*np.exp(power_value) # PDF for QDA\n",
    "        f_x_hat.append(f_x_hat_y)\n",
    "\n",
    "    y_test.append(f_x_hat/np.asarray(f_x_hat).sum()) #probablity disctribution for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save output\n",
    "np.savetxt(\"probs_test.csv\", np.asarray(y_test), delimiter=\",\") # write output to file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
