{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as scp \n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load the user movie ratings dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingDF = pd.read_csv(\"u.csv\", names = [\"user_id\", \"movie_id\", \"rating\"])\n",
    "ratingDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3\n",
       "2       22       377       1\n",
       "3      244        51       2\n",
       "4      166       346       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compute Omega - dictionaries for both users and items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}\n",
    "item_dict = {}\n",
    "\n",
    "for i, rec in ratingDF.iterrows():\n",
    "    if rec['user_id'] not in user_dict:\n",
    "        user_dict[rec['user_id']] = [(rec['movie_id'], rec['rating'])]\n",
    "    else:\n",
    "        user_dict[rec['user_id']].append((rec['movie_id'], rec['rating']))\n",
    "        \n",
    "    if rec['movie_id'] not in item_dict:\n",
    "        item_dict[rec['movie_id']] = [(rec['user_id'], rec['rating'])]\n",
    "    else:\n",
    "        item_dict[rec['movie_id']].append((rec['user_id'], rec['rating']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Descriptive stats..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique users:  943\n",
      "Total unique movies:  1682\n"
     ]
    }
   ],
   "source": [
    "''' Unique userIDs '''\n",
    "print(\"Total unique users: \", len(ratingDF[\"user_id\"].unique()))\n",
    "print(\"Total unique movies: \", len(ratingDF[\"movie_id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MAP inference coordinate ascent algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vj matrix shape:  (1682, 5)\n",
      "uj matrix shape:  (943, 5)\n"
     ]
    }
   ],
   "source": [
    "l_lambda = 2\n",
    "l_sigma = 0.1\n",
    "d = 5\n",
    "\n",
    "''' Initialize all vj based on gaussian distribution '''\n",
    "np.random.seed(100)\n",
    "vj_matrix = multivariate_normal(mean=np.zeros(d), cov=(1/l_lambda) * np.eye(d)).rvs(len(item_dict))\n",
    "ui_matrix = multivariate_normal(mean=np.zeros(d), cov=(1/l_lambda) * np.eye(d)).rvs(len(user_dict))\n",
    "\n",
    "print(\"vj matrix shape: \", vj_matrix.shape)\n",
    "print(\"uj matrix shape: \", ui_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Helper Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_likelihood(p_lambda, p_sigma):\n",
    "    \n",
    "    global user_dict\n",
    "    global ui_matrix\n",
    "    global vj_matrix\n",
    "    \n",
    "    loss = 0.0\n",
    "    \n",
    "    for user_id in user_dict:\n",
    "        ui = user_id - 1\n",
    "        for movie_id, mij in user_dict[user_id]:\n",
    "            vj = movie_id - 1\n",
    "            predicted_mij = np.dot(ui_matrix[ui], vj_matrix[vj])\n",
    "            ratting_diff = (1/(2 * p_sigma * p_sigma)) * ((mij - predicted_mij) **2)\n",
    "            loss += ratting_diff\n",
    "    \n",
    "    ''' Compute user norm & item norm'''\n",
    "    total_ui_norm = 0.0\n",
    "    for ui in ui_matrix:\n",
    "        user_norm = (p_lambda/2) * np.linalg.norm(ui)\n",
    "        total_ui_norm += user_norm\n",
    "        \n",
    "    total_vj_norm = 0.0\n",
    "    for vj in vj_matrix:\n",
    "        user_norm = (p_lambda/2) * np.linalg.norm(vj)\n",
    "        total_vj_norm += user_norm\n",
    "        \n",
    "    return -1 * (loss + total_ui_norm + total_vj_norm)\n",
    "\n",
    "def update_user_location(num_dimensions, p_lambda, p_sigma):\n",
    "    ''' Updating user location \n",
    "    '''\n",
    "    global user_dict\n",
    "    global vj_matrix\n",
    "    global ui_matrix\n",
    "    \n",
    "    for idx in range(len(user_dict)):\n",
    "    \n",
    "        user_id = idx + 1\n",
    "        mapping_arr = np.array(user_dict[user_id])\n",
    "        vj_list = mapping_arr[:, 0] - 1\n",
    "        ratings = mapping_arr[:, 1]\n",
    "\n",
    "        first_sub_part_1 = p_lambda * np.power(p_sigma, 2) * np.eye(num_dimensions)\n",
    "        \n",
    "        first_sub_part_2 = np.sum(np.array([np.outer(vj_matrix[vj_list][i], vj_matrix[vj_list][i]) \\\n",
    "                                  for i in range(vj_matrix[vj_list].shape[0])]), axis = 0)\n",
    "\n",
    "        first_part = first_sub_part_1 + first_sub_part_2\n",
    "        second_part = np.sum(ratings.reshape(-1, 1) * vj_matrix[vj_list], axis = 0)\n",
    "        \n",
    "        ''' update user-id mapping\n",
    "            multiply first part inverse & second part\n",
    "        '''\n",
    "        ui = np.matmul(np.linalg.inv(first_part), second_part.reshape(-1, 1))\n",
    "        ui_matrix[idx] = np.squeeze(ui)\n",
    "        \n",
    "def update_item_location(num_dimensions, p_lambda, p_sigma):\n",
    "    ''' Updating item location \n",
    "    '''\n",
    "    \n",
    "    global item_dict\n",
    "    global vj_matrix\n",
    "    global ui_matrix\n",
    "    \n",
    "    for idx in range(len(item_dict)):\n",
    "    \n",
    "        item_id = idx + 1\n",
    "        mapping_arr = np.array(item_dict[item_id])\n",
    "        ui_list = mapping_arr[:, 0] - 1\n",
    "        ratings = mapping_arr[:, 1]\n",
    "\n",
    "        first_sub_part_1 = p_lambda * np.power(p_sigma, 2) * np.eye(num_dimensions)\n",
    "        temp = [np.outer(ui_matrix[ui_list][i], ui_matrix[ui_list][i]) for i in range(ui_matrix[ui_list].shape[0])]\n",
    "        first_sub_part_2 = np.sum(np.array(temp), axis = 0)\n",
    "\n",
    "        first_part = first_sub_part_1 + first_sub_part_2\n",
    "        second_part = np.sum(ratings.reshape(-1, 1) * ui_matrix[ui_list], axis = 0)\n",
    "\n",
    "        ''' update item-id mapping\n",
    "            multiply first part inverse & second part\n",
    "        '''\n",
    "        vj = np.matmul(np.linalg.inv(first_part), second_part.reshape(-1, 1))\n",
    "        vj_matrix[idx] = np.squeeze(vj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Main training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num: 1, loss: -75204183.60398236\n",
      "iteration num: 2, loss: -30361025.340819918\n",
      "iteration num: 3, loss: -4543629.781865825\n",
      "iteration num: 4, loss: -3549122.9451645385\n",
      "iteration num: 5, loss: -3336364.5658949795\n",
      "iteration num: 6, loss: -3248537.181796049\n",
      "iteration num: 7, loss: -3203951.4148401474\n",
      "iteration num: 8, loss: -3177132.4233412785\n",
      "iteration num: 9, loss: -3158407.886837847\n",
      "iteration num: 10, loss: -3144992.9298362583\n",
      "iteration num: 11, loss: -3134959.192335728\n",
      "iteration num: 12, loss: -3126852.719301725\n",
      "iteration num: 13, loss: -3120036.480098249\n",
      "iteration num: 14, loss: -3114147.487439035\n",
      "iteration num: 15, loss: -3108948.003045908\n",
      "iteration num: 16, loss: -3104345.883391726\n",
      "iteration num: 17, loss: -3100301.3996450338\n",
      "iteration num: 18, loss: -3096759.358911876\n",
      "iteration num: 19, loss: -3093750.1958260387\n",
      "iteration num: 20, loss: -3091194.200070084\n",
      "iteration num: 21, loss: -3088933.491402721\n",
      "iteration num: 22, loss: -3086906.7133455756\n",
      "iteration num: 23, loss: -3085086.748137283\n",
      "iteration num: 24, loss: -3083341.590384203\n",
      "iteration num: 25, loss: -3081558.4247570615\n",
      "iteration num: 26, loss: -3080133.6701015835\n",
      "iteration num: 27, loss: -3078904.2416284773\n",
      "iteration num: 28, loss: -3077786.6419151817\n",
      "iteration num: 29, loss: -3076721.31963202\n",
      "iteration num: 30, loss: -3075725.881921159\n",
      "iteration num: 31, loss: -3074854.1282925205\n",
      "iteration num: 32, loss: -3074073.253701973\n",
      "iteration num: 33, loss: -3073349.1097553596\n",
      "iteration num: 34, loss: -3072664.6057117493\n",
      "iteration num: 35, loss: -3072039.600661499\n",
      "iteration num: 36, loss: -3071470.4865492457\n",
      "iteration num: 37, loss: -3070935.2095969655\n",
      "iteration num: 38, loss: -3070426.253943124\n",
      "iteration num: 39, loss: -3069948.108109504\n",
      "iteration num: 40, loss: -3069492.9033758803\n",
      "iteration num: 41, loss: -3069065.4194776486\n",
      "iteration num: 42, loss: -3068667.31125189\n",
      "iteration num: 43, loss: -3068291.026110979\n",
      "iteration num: 44, loss: -3067929.1227493444\n",
      "iteration num: 45, loss: -3067568.989760739\n",
      "iteration num: 46, loss: -3067184.61068466\n",
      "iteration num: 47, loss: -3066747.172965693\n",
      "iteration num: 48, loss: -3066295.94650941\n",
      "iteration num: 49, loss: -3065844.0871772333\n",
      "iteration num: 50, loss: -3065345.092610512\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(50):\n",
    "    loss = compute_joint_likelihood(l_lambda, l_sigma)\n",
    "    print(\"iteration num: {}, loss: {}\".format(iteration + 1, loss))\n",
    "    update_user_location(d, l_lambda, l_sigma)\n",
    "    update_item_location(d, l_lambda, l_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compute rating and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.015008758302338"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Compute rating between user id 3 & movie id 302'''\n",
    "np.dot(ui_matrix[2], vj_matrix[301])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
